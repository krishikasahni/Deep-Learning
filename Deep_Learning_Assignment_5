{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14819202,
          "sourceType": "datasetVersion",
          "datasetId": 9477007
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishikasahni/Deep-Learning/blob/main/Deep_Learning_Assignment_5\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import time\n",
        "from collections import Counter"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:45:44.238414Z",
          "iopub.execute_input": "2026-02-12T14:45:44.238655Z",
          "iopub.status.idle": "2026-02-12T14:45:49.247127Z",
          "shell.execute_reply.started": "2026-02-12T14:45:44.238618Z",
          "shell.execute_reply": "2026-02-12T14:45:49.246262Z"
        },
        "id": "TVP45soxbIJy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 1: Implement a basic RNN from\n",
        "scratch using NumPy to understand the internal workings of recurrent\n",
        "neural networks."
      ],
      "metadata": {
        "id": "2TUmPRCjbIJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:46:49.602885Z",
          "iopub.execute_input": "2026-02-12T14:46:49.603483Z",
          "iopub.status.idle": "2026-02-12T14:46:49.610615Z",
          "shell.execute_reply.started": "2026-02-12T14:46:49.603452Z",
          "shell.execute_reply": "2026-02-12T14:46:49.609949Z"
        },
        "id": "NbRD66hibIJ2",
        "outputId": "09d7b766-dbf9-4fed-8ac9-52d786df8b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/poems-100-csv/poems-100.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/kaggle/input/poems-100-csv/poems-100.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "print(text[:500])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:47:10.694948Z",
          "iopub.execute_input": "2026-02-12T14:47:10.695677Z",
          "iopub.status.idle": "2026-02-12T14:47:10.708275Z",
          "shell.execute_reply.started": "2026-02-12T14:47:10.695649Z",
          "shell.execute_reply": "2026-02-12T14:47:10.707468Z"
        },
        "id": "alwePHY3bIJ3",
        "outputId": "f0167a5a-3771-40bd-add5-714d5d918a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "text\n\"o my luve's like a red, red rose\nthat’s newly sprung in june;\no my luve's like the melodie\nthat’s sweetly play'd in tune.\n\nas fair art thou, my bonnie lass,\nso deep in luve am i:\nand i will luve thee still, my dear,\ntill a’ the seas gang dry:\n\ntill a’ the seas gang dry, my dear,\nand the rocks melt wi’ the sun:\ni will luve thee still, my dear,\nwhile the sands o’ life shall run.\n\nand fare thee well, my only luve\nand fare thee well, a while!\nand i will come again, my luve,\ntho’ it were ten th\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "print(text[:300])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:47:29.056751Z",
          "iopub.execute_input": "2026-02-12T14:47:29.057400Z",
          "iopub.status.idle": "2026-02-12T14:47:29.074972Z",
          "shell.execute_reply.started": "2026-02-12T14:47:29.057369Z",
          "shell.execute_reply": "2026-02-12T14:47:29.074167Z"
        },
        "id": "S0HYQgL-bIJ3",
        "outputId": "bc21573f-92f7-4e54-af13-9cf4253b120f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "text o my luves like a red red rose thats newly sprung in june o my luves like the melodie thats sweetly playd in tune as fair art thou my bonnie lass so deep in luve am i and i will luve thee still my dear till a the seas gang dry till a the seas gang dry my dear and the rocks melt wi the sun i wil\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "word_counts = Counter(words)\n",
        "common_words = [word for word, count in word_counts.most_common(5000)]\n",
        "\n",
        "words = [word for word in words if word in common_words]\n",
        "\n",
        "vocab = sorted(set(words))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word2idx = {word:i for i, word in enumerate(vocab)}\n",
        "idx2word = {i:word for word, i in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:48:57.129959Z",
          "iopub.execute_input": "2026-02-12T14:48:57.130353Z",
          "iopub.status.idle": "2026-02-12T14:48:57.347431Z",
          "shell.execute_reply.started": "2026-02-12T14:48:57.130312Z",
          "shell.execute_reply": "2026-02-12T14:48:57.346614Z"
        },
        "id": "HaUjF2kRbIJ4",
        "outputId": "e838c99d-336d-45bc-e3e1-b90639774730"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Vocabulary Size: 5000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 5\n",
        "data = []\n",
        "\n",
        "for i in range(len(words) - seq_length):\n",
        "    input_seq = words[i:i+seq_length]\n",
        "    target = words[i+seq_length]\n",
        "    data.append((input_seq, target))\n",
        "\n",
        "print(\"Total sequences:\", len(data))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:49:09.979823Z",
          "iopub.execute_input": "2026-02-12T14:49:09.980135Z",
          "iopub.status.idle": "2026-02-12T14:49:10.101033Z",
          "shell.execute_reply.started": "2026-02-12T14:49:09.980107Z",
          "shell.execute_reply": "2026-02-12T14:49:10.100196Z"
        },
        "id": "LzsnyhJ-bIJ4",
        "outputId": "343f334a-efa2-40cf-91f2-36d9040aad53"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total sequences: 24232\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(word):\n",
        "    vec = np.zeros(vocab_size)\n",
        "    vec[word2idx[word]] = 1\n",
        "    return vec\n",
        "\n",
        "class RNN_Scratch:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h = np.zeros((self.hidden_size, 1))\n",
        "\n",
        "        for word in inputs:\n",
        "            x = one_hot(word).reshape(-1,1)\n",
        "            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n",
        "\n",
        "        y = np.dot(self.Why, h) + self.by\n",
        "        return y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:49:29.712889Z",
          "iopub.execute_input": "2026-02-12T14:49:29.713495Z",
          "iopub.status.idle": "2026-02-12T14:49:29.719435Z",
          "shell.execute_reply.started": "2026-02-12T14:49:29.713467Z",
          "shell.execute_reply": "2026-02-12T14:49:29.718801Z"
        },
        "id": "1HAJDS-VbIJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_scratch = RNN_Scratch(vocab_size, 100, vocab_size)\n",
        "sample_input, sample_target = data[0]\n",
        "output = rnn_scratch.forward(sample_input)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:49:39.264077Z",
          "iopub.execute_input": "2026-02-12T14:49:39.264660Z",
          "iopub.status.idle": "2026-02-12T14:49:39.307975Z",
          "shell.execute_reply.started": "2026-02-12T14:49:39.264631Z",
          "shell.execute_reply": "2026-02-12T14:49:39.307440Z"
        },
        "id": "yRkrSw5MbIJ6",
        "outputId": "64df73a0-f773-4406-8287-e2eeb3bae266"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Output shape: (5000, 1)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: One Hot Encoding"
      ],
      "metadata": {
        "id": "d_1ZqS_BbIJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for input_seq, target in data:\n",
        "    seq = []\n",
        "    for word in input_seq:\n",
        "        vec = np.zeros(vocab_size)\n",
        "        vec[word2idx[word]] = 1\n",
        "        seq.append(vec)\n",
        "    X.append(seq)\n",
        "    Y.append(word2idx[target])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_onehot = torch.tensor(X, dtype=torch.float32)\n",
        "Y_onehot = torch.tensor(Y, dtype=torch.long)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:57:38.022152Z",
          "iopub.execute_input": "2026-02-12T14:57:38.022474Z",
          "iopub.status.idle": "2026-02-12T14:57:41.655476Z",
          "shell.execute_reply.started": "2026-02-12T14:57:38.022444Z",
          "shell.execute_reply": "2026-02-12T14:57:41.654601Z"
        },
        "id": "8fgRvmy5bIJ6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:57:57.576397Z",
          "iopub.execute_input": "2026-02-12T14:57:57.577012Z",
          "iopub.status.idle": "2026-02-12T14:57:57.582015Z",
          "shell.execute_reply.started": "2026-02-12T14:57:57.576978Z",
          "shell.execute_reply": "2026-02-12T14:57:57.581303Z"
        },
        "id": "foT9H5r3bIJ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "dataset = TensorDataset(X_onehot, Y_onehot)\n",
        "\n",
        "batch_size = 128   # safe size\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_onehot = RNN_OneHot(vocab_size, 128, vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_onehot.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_onehot(xb)\n",
        "        loss = criterion(output, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T14:59:29.258179Z",
          "iopub.execute_input": "2026-02-12T14:59:29.258477Z",
          "iopub.status.idle": "2026-02-12T14:59:32.571593Z",
          "shell.execute_reply.started": "2026-02-12T14:59:29.258452Z",
          "shell.execute_reply": "2026-02-12T14:59:32.570762Z"
        },
        "id": "6IrUVdoYbIJ7",
        "outputId": "e80c4815-dc3e-4d9d-c8b9-8d3bc39da542"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1, Loss: 6.992644553435476\nEpoch 2, Loss: 6.486676785820409\nEpoch 3, Loss: 6.282511123858\nEpoch 4, Loss: 6.0563562393188475\nEpoch 5, Loss: 5.837920048362331\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 3: Trainable Word Embeddings Approach"
      ],
      "metadata": {
        "id": "y841xSnjbIJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_idx = []\n",
        "Y_idx = []\n",
        "\n",
        "for input_seq, target in data:\n",
        "    seq = [word2idx[word] for word in input_seq]\n",
        "    X_idx.append(seq)\n",
        "    Y_idx.append(word2idx[target])\n",
        "\n",
        "X_idx = torch.tensor(X_idx).to(device)\n",
        "Y_idx = torch.tensor(Y_idx).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T15:00:16.527527Z",
          "iopub.execute_input": "2026-02-12T15:00:16.528578Z",
          "iopub.status.idle": "2026-02-12T15:00:16.586999Z",
          "shell.execute_reply.started": "2026-02-12T15:00:16.528535Z",
          "shell.execute_reply": "2026-02-12T15:00:16.586390Z"
        },
        "id": "L5TF9VVBbIJ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T15:00:24.795216Z",
          "iopub.execute_input": "2026-02-12T15:00:24.795942Z",
          "iopub.status.idle": "2026-02-12T15:00:24.800873Z",
          "shell.execute_reply.started": "2026-02-12T15:00:24.795913Z",
          "shell.execute_reply": "2026-02-12T15:00:24.800202Z"
        },
        "id": "YpRXbkeObIJ9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = RNN_Embedding(vocab_size, 100, 128).to(device)\n",
        "optimizer = optim.Adam(model_embed.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    output = model_embed(X_idx)\n",
        "    loss = criterion(output, Y_idx)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-12T15:00:35.346320Z",
          "iopub.execute_input": "2026-02-12T15:00:35.346941Z",
          "iopub.status.idle": "2026-02-12T15:00:35.899744Z",
          "shell.execute_reply.started": "2026-02-12T15:00:35.346911Z",
          "shell.execute_reply": "2026-02-12T15:00:35.899110Z"
        },
        "id": "w2F-z04obIJ9",
        "outputId": "ee5de1c7-bc2b-4983-d90b-e26a4561b113"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1, Loss: 8.551536560058594\nEpoch 2, Loss: 8.514703750610352\nEpoch 3, Loss: 8.477775573730469\nEpoch 4, Loss: 8.439837455749512\nEpoch 5, Loss: 8.399864196777344\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 4: • Compare the training time and loss for both methods.\n",
        "• Evaluate the quality of generated text.\n",
        "• Discuss the advantages and disadvantages of each approach."
      ],
      "metadata": {
        "id": "cLNKj0mRbIJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot:-\n",
        "\n",
        "1. High dimensional\n",
        "2. Slower\n",
        "3. No semantic meaning\n",
        "\n",
        "Embeddings:-\n",
        "\n",
        "1. Lower dimension\n",
        "2. Faster\n",
        "3. Learns word relationships\n",
        "4. Better text generation"
      ],
      "metadata": {
        "id": "i2YYga--bIJ-"
      }
    }
  ]
}